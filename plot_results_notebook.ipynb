{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Walk Results Visualization\n",
    "\n",
    "This notebook provides tools for plotting and analyzing forward walk forecasting results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Configure matplotlib for better plots\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forward_results(csv_file, model_name=\"Model\", save_path=None):\n",
    "    \"\"\"\n",
    "    Plot forward walk results showing actual vs forecasted values\n",
    "    \n",
    "    Args:\n",
    "        csv_file: Path to CSV file with columns: step, actual, forecast, absolute_error\n",
    "        model_name: Name of the model for plot title\n",
    "        save_path: Path to save the plot (optional)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.plot(df['step'], df['actual'], 'b-', label='Actual', marker='o', markersize=4)\n",
    "    plt.plot(df['step'], df['forecast'], 'r--', label='Forecast', marker='s', markersize=4)\n",
    "    \n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'{model_name} Forward Walk Results: Actual vs Forecast')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Mean Absolute Error: {df['absolute_error'].mean():.6f}\")\n",
    "    print(f\"Max Absolute Error: {df['absolute_error'].max():.6f}\")\n",
    "    print(f\"Min Absolute Error: {df['absolute_error'].min():.6f}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to forward walk results\n",
    "base_dir = \"run_forward\"\n",
    "\n",
    "naive_file = os.path.join(base_dir, \"naive_walk_forward_results.csv\")\n",
    "nbeats_file = os.path.join(base_dir, \"nbeats_walk_forward_results.csv\")\n",
    "\n",
    "# Check if files exist\n",
    "print(f\"Naive results file exists: {os.path.exists(naive_file)}\")\n",
    "print(f\"NBEATS results file exists: {os.path.exists(nbeats_file)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot NBEATS Forward Walk Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot NBEATS results\n",
    "print(\"Plotting NBEATS forward walk results...\")\n",
    "\n",
    "if os.path.exists(nbeats_file):\n",
    "    nbeats_df = plot_forward_results(\n",
    "        nbeats_file, \n",
    "        model_name=\"NBEATS\",\n",
    "        save_path=\"nbeats_forward_walk_plot.png\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"NBEATS results file not found: {nbeats_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot Naive Forward Walk Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Naive results\n",
    "print(\"Plotting Naive forward walk results...\")\n",
    "\n",
    "if os.path.exists(naive_file):\n",
    "    naive_df = plot_forward_results(\n",
    "        naive_file,\n",
    "        model_name=\"Naive\", \n",
    "        save_path=\"naive_forward_walk_plot.png\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"Naive results file not found: {naive_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Models (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models side by side if both datasets are available\n",
    "if 'nbeats_df' in locals() and 'naive_df' in locals():\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "    # NBEATS plot\n",
    "    ax1.plot(nbeats_df['step'], nbeats_df['actual'], 'b-', label='Actual', marker='o', markersize=3)\n",
    "    ax1.plot(nbeats_df['step'], nbeats_df['forecast'], 'r--', label='Forecast', marker='s', markersize=3)\n",
    "    ax1.set_title('NBEATS: Actual vs Forecast')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylabel('Value')\n",
    "    \n",
    "    # Naive plot\n",
    "    ax2.plot(naive_df['step'], naive_df['actual'], 'b-', label='Actual', marker='o', markersize=3)\n",
    "    ax2.plot(naive_df['step'], naive_df['forecast'], 'r--', label='Forecast', marker='s', markersize=3)\n",
    "    ax2.set_title('Naive: Actual vs Forecast')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlabel('Time Step')\n",
    "    ax2.set_ylabel('Value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print comparison statistics\n",
    "    print(\"\\n=== Model Comparison ===\")\n",
    "    print(f\"NBEATS MAE: {nbeats_df['absolute_error'].mean():.6f}\")\n",
    "    print(f\"Naive MAE:  {naive_df['absolute_error'].mean():.6f}\")\n",
    "    \n",
    "    mae_improvement = ((naive_df['absolute_error'].mean() - nbeats_df['absolute_error'].mean()) / \n",
    "                       naive_df['absolute_error'].mean()) * 100\n",
    "    print(f\"NBEATS improvement over Naive: {mae_improvement:.2f}%\")\n",
    "else:\n",
    "    print(\"Comparison requires both model results to be loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed error analysis for available models\n",
    "models_data = {}\n",
    "\n",
    "if 'nbeats_df' in locals():\n",
    "    models_data['NBEATS'] = nbeats_df\n",
    "if 'naive_df' in locals():\n",
    "    models_data['Naive'] = naive_df\n",
    "\n",
    "if models_data:\n",
    "    # Plot error distributions\n",
    "    fig, axes = plt.subplots(1, len(models_data), figsize=(6*len(models_data), 5))\n",
    "    if len(models_data) == 1:\n",
    "        axes = [axes]  # Make it iterable for single model\n",
    "    \n",
    "    for i, (model_name, df) in enumerate(models_data.items()):\n",
    "        axes[i].hist(df['absolute_error'], bins=20, alpha=0.7, edgecolor='black')\n",
    "        axes[i].set_title(f'{model_name} - Error Distribution')\n",
    "        axes[i].set_xlabel('Absolute Error')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics text\n",
    "        mean_err = df['absolute_error'].mean()\n",
    "        std_err = df['absolute_error'].std()\n",
    "        axes[i].axvline(mean_err, color='red', linestyle='--', \n",
    "                       label=f'Mean: {mean_err:.4f}')\n",
    "        axes[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('error_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics table\n",
    "    print(\"\\n=== Error Statistics Summary ===\")\n",
    "    summary_data = []\n",
    "    for model_name, df in models_data.items():\n",
    "        summary_data.append({\n",
    "            'Model': model_name,\n",
    "            'Mean Error': f\"{df['absolute_error'].mean():.6f}\",\n",
    "            'Std Error': f\"{df['absolute_error'].std():.6f}\",\n",
    "            'Max Error': f\"{df['absolute_error'].max():.6f}\",\n",
    "            'Min Error': f\"{df['absolute_error'].min():.6f}\"\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(summary_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No model data available for error analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Custom Plotting (Optional)\n",
    "\n",
    "Use this cell to create custom plots or analyze specific aspects of your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Plot just a subset of time steps\n",
    "# Modify this cell as needed for your specific analysis\n",
    "\n",
    "# Uncomment and modify the code below for custom analysis:\n",
    "\n",
    "# if 'nbeats_df' in locals():\n",
    "#     # Plot only first 50 time steps\n",
    "#     subset_df = nbeats_df.head(50)\n",
    "#     \n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.plot(subset_df['step'], subset_df['actual'], 'b-', label='Actual', marker='o')\n",
    "#     plt.plot(subset_df['step'], subset_df['forecast'], 'r--', label='Forecast', marker='s')\n",
    "#     plt.title('NBEATS Results (First 50 Steps)')\n",
    "#     plt.xlabel('Time Step')\n",
    "#     plt.ylabel('Value')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True, alpha=0.3)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "print(\"Add your custom plotting code in this cell.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}